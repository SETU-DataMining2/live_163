{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Texas Hospital Discharge - Import"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from scipy import stats\n",
    "import yaml, time, sys, os, glob\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "pd.set_option('display.max_columns', None)  \n",
    "\n",
    "DATASET = \"Texas_Inpatient_Discharge\"\n",
    "SPLIT_TRAINING = True\n",
    "DEBUG = False\n",
    "SEED = 42\n",
    "\n",
    "COLAB = 'google.colab' in sys.modules\n",
    "if COLAB:\n",
    "    ROOT = f\"/content/gdrive/MyDrive/datasets/{DATASET.replace(' ','_')}/\"\n",
    "else:\n",
    "    ROOT = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  from google.colab import drive\n",
    "  if not os.path.isdir(\"/content/gdrive\"):\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    d = \"/content/gdrive/MyDrive/datasets\"\n",
    "    if not os.path.isdir(d): os.makedirs(d)\n",
    "  if not os.path.isdir(ROOT): os.makedirs(ROOT)\n",
    "\n",
    "def makedirs(d):\n",
    "  if COLAB:\n",
    "    if not os.path.isdir(ROOT+d): os.makedirs(ROOT+d)\n",
    "  else:\n",
    "    if not os.path.isdir(ROOT+d): os.makedirs(ROOT+d, mode=0o777, exist_ok=True)\n",
    "\n",
    "for d in ['doc','orig','data','output']: makedirs(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local copy of my_lib.py in folder .\n",
      "Using local copy of train.csv.gz in folder orig\n",
      "Using local copy of grading.csv.gz in folder orig\n",
      "Using local copy of Facility_type1q2013_tab.zip in folder orig\n",
      "Using local copy of Facility_type2q2013_tab.zip in folder orig\n",
      "Using local copy of Facility_type3q2013_tab.zip in folder orig\n",
      "Using local copy of Facility_type4q2013_tab.zip in folder orig\n",
      "Using local copy of UserManual1Q2013.pdf in folder doc\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://setu-datamining2.github.io/live/topics/21-Assignments/03-Texas_Inpatient_Discharge/files/\"\n",
    "\n",
    "files = \"my_lib.py train.csv.gz grading.csv.gz Facility_type1q2013_tab.zip Facility_type2q2013_tab.zip Facility_type3q2013_tab.zip Facility_type4q2013_tab.zip UserManual1Q2013.pdf\"\n",
    "\n",
    "for filename in files.split(\" \"):\n",
    "    \n",
    "    ext = filename.split(\".\")[-1]\n",
    "    dest = {\"pdf\":\"doc\", \"py\":\".\", \"ipynb\":\".\", \"gz\":\"orig\", \"zip\":\"orig\"}[ext]\n",
    "   \n",
    "    source = f\"{URL}/{filename}\"\n",
    "    target = f\"{ROOT}/{dest}/{filename}\"\n",
    "\n",
    "    if not os.path.isfile(target):\n",
    "        print (f\"Downloading remote file {filename}\", sep=\"\")\n",
    "        import urllib.request\n",
    "        urllib.request.urlretrieve(source, target)\n",
    "    else:\n",
    "        print(f\"Using local copy of {filename} in folder {dest}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import my_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 194)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{ROOT}/orig/train.csv.gz\", dtype=str)\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Suggestion: Dataset is waaaay too big - everything is going to be slow => split into smaller sets for development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 1.2. Construct Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     999698\n",
       "unique       382\n",
       "top         0002\n",
       "freq      259935\n",
       "Name: LENGTH_OF_STAY, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.LENGTH_OF_STAY.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Drop row with target (LENGTH_OF_STAY) missing values\n",
    "df.dropna(subset=[\"LENGTH_OF_STAY\"], inplace=True)\n",
    "\n",
    "# Convert to int\n",
    "df.LENGTH_OF_STAY = df.LENGTH_OF_STAY.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    999698.000000\n",
       "mean          5.280482\n",
       "std          11.420006\n",
       "min           1.000000\n",
       "25%           2.000000\n",
       "50%           3.000000\n",
       "75%           6.000000\n",
       "max        1961.000000\n",
       "Name: LENGTH_OF_STAY, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.LENGTH_OF_STAY.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df[\"TARGET\"] = df.LENGTH_OF_STAY.apply(lambda x: \"short\" if x < 3 else (\"medium\" if x <= 6 else \"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "short     414152\n",
       "medium    381437\n",
       "long      204109\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TARGET.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 1.3. Dividing training datasets into subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomising order ...\n",
      "\n",
      "Break dataset into 20 each with 49984 rows ... 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "Break dataset into 10 each with 99969 rows ... 0 1 2 3 4 5 6 7 8 9 \n",
      "Break dataset into 5 each with 199939 rows ... 0 1 2 3 4 \n",
      "Break dataset into 2 each with 499849 rows ... 0 1 \n",
      "Break dataset into 1 each with 999698 rows ... 0 "
     ]
    }
   ],
   "source": [
    "if SPLIT_TRAINING:\n",
    "    \n",
    "    # Randomising the rows in the dataset\n",
    "    print(\"Randomising order ...\")\n",
    "    df_sample = df.sample(frac=1, random_state=SEED)\n",
    "    \n",
    "    for parts in [10,5,2,1]:\n",
    "        nrows = df.shape[0] // parts\n",
    "        print(f\"\\nBreak dataset into {parts} each with {nrows} rows ... \", end=\"\")\n",
    "\n",
    "        for k in range(parts):\n",
    "            filename = f\"{ROOT}/data/df_train_sample_%02d_of_%d.csv\" % (k, parts)\n",
    "\n",
    "            print(k, end=\" \")\n",
    "            df_sample.iloc[k * nrows : (k + 1) * nrows].to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Dividing the training dataset into subsets will make EDA more performant and easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!say \"splits are saved\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Faculty Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '{ROOT}/orig/Facility_type1q2013_tab.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kmurphy/wit/archive/2022-23/modules/Data_Mining_2/datasets/90-Texas_Inpatient_Discharge/01-Import.ipynb Cell 21\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kmurphy/wit/archive/2022-23/modules/Data_Mining_2/datasets/90-Texas_Inpatient_Discharge/01-Import.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_f \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m{ROOT}\u001b[39;49;00m\u001b[39m/orig/Facility_type1q2013_tab.zip\u001b[39;49m\u001b[39m\"\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kmurphy/wit/archive/2022-23/modules/Data_Mining_2/datasets/90-Texas_Inpatient_Discharge/01-Import.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(df_f\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kmurphy/wit/archive/2022-23/modules/Data_Mining_2/datasets/90-Texas_Inpatient_Discharge/01-Import.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_f\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     f,\n\u001b[1;32m   1219\u001b[0m     mode,\n\u001b[1;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1226\u001b[0m )\n\u001b[1;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/pandas/io/common.py:743\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[39m# ZIP Compression\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39melif\u001b[39;00m compression \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    740\u001b[0m     \u001b[39m# error: Argument 1 to \"_BytesZipFile\" has incompatible type \"Union[str,\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[39m# BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;00m\n\u001b[1;32m    742\u001b[0m     \u001b[39m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;00m\n\u001b[0;32m--> 743\u001b[0m     handle \u001b[39m=\u001b[39m _BytesZipFile(\n\u001b[1;32m    744\u001b[0m         handle, ioargs\u001b[39m.\u001b[39;49mmode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcompression_args  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m     )\n\u001b[1;32m    746\u001b[0m     \u001b[39mif\u001b[39;00m handle\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    747\u001b[0m         handles\u001b[39m.\u001b[39mappend(handle)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/site-packages/pandas/io/common.py:890\u001b[0m, in \u001b[0;36m_BytesZipFile.__init__\u001b[0;34m(self, file, mode, archive_name, **kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m kwargs_zip\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m    886\u001b[0m \u001b[39m# error: Argument 1 to \"__init__\" of \"ZipFile\" has incompatible type\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39m# \"Union[_PathLike[str], Union[str, Union[IO[Any], RawIOBase, BufferedIOBase,\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \u001b[39m# TextIOBase, TextIOWrapper, mmap]]]\"; expected \"Union[Union[str,\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \u001b[39m# _PathLike[str]], IO[bytes]]\"\u001b[39;00m\n\u001b[0;32m--> 890\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(file, mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_zip)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/zipfile.py:1239\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m   1238\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1239\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mopen(file, filemode)\n\u001b[1;32m   1240\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m   1241\u001b[0m         \u001b[39mif\u001b[39;00m filemode \u001b[39min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '{ROOT}/orig/Facility_type1q2013_tab.zip'"
     ]
    }
   ],
   "source": [
    "df_f = pd.read_csv(\"{ROOT}/orig/Facility_type1q2013_tab.zip\", sep=\"\\t\")\n",
    "print(df_f.shape)\n",
    "df_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_fs = [pd.read_csv(f\"{ROOT}/orig/Facility_type{k}q2013_tab.zip\", sep=\"\\t\") for k in range(1,5) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(577, 11)\n",
      "(584, 11)\n",
      "(587, 11)\n",
      "(587, 11)\n"
     ]
    }
   ],
   "source": [
    "for d in df_fs:\n",
    "    print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2335, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f = pd.concat(df_fs, ignore_index=True)\n",
    "df_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.drop_duplicates(keep=\"last\", inplace=True)\n",
    "df_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.drop_duplicates(subset=\"THCIC_ID\", keep=\"last\", inplace=True)\n",
    "df_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['THCIC_ID', 'PROVIDER_NAME', 'FAC_TEACHING_IND', 'FAC_PSYCH_IND',\n",
       "       'FAC_REHAB_IND', 'FAC_ACUTE_CARE_IND', 'FAC_SNF_IND',\n",
       "       'FAC_LONG_TERM_AC_IND', 'FAC_OTHER_LTC_IND', 'FAC_PEDS_IND',\n",
       "       'Unnamed: 10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_f.drop(columns=[\"Unnamed: 10\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_f.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for c in df_f.columns[2:]:\n",
    "    df_f[c] = df_f[c].map({0:0, \"A\":1, \"C\":1, \"X\":1 ,\"x\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>THCIC_ID</th>\n",
       "      <th>PROVIDER_NAME</th>\n",
       "      <th>FAC_TEACHING_IND</th>\n",
       "      <th>FAC_PSYCH_IND</th>\n",
       "      <th>FAC_REHAB_IND</th>\n",
       "      <th>FAC_ACUTE_CARE_IND</th>\n",
       "      <th>FAC_SNF_IND</th>\n",
       "      <th>FAC_LONG_TERM_AC_IND</th>\n",
       "      <th>FAC_OTHER_LTC_IND</th>\n",
       "      <th>FAC_PEDS_IND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>724900</td>\n",
       "      <td>Brownsville Doctors Hospital</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>854000</td>\n",
       "      <td>Twin Creeks Hospital</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>907000</td>\n",
       "      <td>Renaissance Hospital-Groves</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>939000</td>\n",
       "      <td>GlobalRehab Hospital-San Antonio</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>798500</td>\n",
       "      <td>Austin Surgical Hospital</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     THCIC_ID                     PROVIDER_NAME  FAC_TEACHING_IND  \\\n",
       "347    724900      Brownsville Doctors Hospital                 0   \n",
       "499    854000              Twin Creeks Hospital                 0   \n",
       "531    907000       Renaissance Hospital-Groves                 0   \n",
       "544    939000  GlobalRehab Hospital-San Antonio                 0   \n",
       "983    798500          Austin Surgical Hospital                 0   \n",
       "\n",
       "     FAC_PSYCH_IND  FAC_REHAB_IND  FAC_ACUTE_CARE_IND  FAC_SNF_IND  \\\n",
       "347              0              0                   1            0   \n",
       "499              0              1                   0            0   \n",
       "531              0              0                   1            0   \n",
       "544              0              1                   0            0   \n",
       "983              0              0                   0            0   \n",
       "\n",
       "     FAC_LONG_TERM_AC_IND  FAC_OTHER_LTC_IND  FAC_PEDS_IND  \n",
       "347                     0                  0             1  \n",
       "499                     0                  0             0  \n",
       "531                     0                  0             0  \n",
       "544                     0                  0             0  \n",
       "983                     0                  0             1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_f.to_csv(f\"{ROOT}/data/facility.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "THCIC_ID                                                        342296121\n",
       "PROVIDER_NAME           Brownsville Doctors HospitalTwin Creeks Hospit...\n",
       "FAC_TEACHING_IND                                                       42\n",
       "FAC_PSYCH_IND                                                          94\n",
       "FAC_REHAB_IND                                                         164\n",
       "FAC_ACUTE_CARE_IND                                                    396\n",
       "FAC_SNF_IND                                                            51\n",
       "FAC_LONG_TERM_AC_IND                                                   99\n",
       "FAC_OTHER_LTC_IND                                                       4\n",
       "FAC_PEDS_IND                                                           99\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
