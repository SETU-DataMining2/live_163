<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Data Mining 2</title>

    <!-- Bootstrap core CSS -->
    <link href="../../../style/bootstrap/css/bootstrap.min.css" rel="stylesheet">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../../../style/codehilite/css/default.css" rel="stylesheet">
    <link href="../../../style/misc/css/module.css" rel="stylesheet">
    <link href="../../../style/misc/css/practical.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

	<script type="text/javascript"
	  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>

  </head>

<body>

	<!-- Fixed navbar -->
	<div class="navbar navbar-default navbar-fixed-top" role="navigation">
		<div class="container">
			
			
	    	<div class="collapse navbar-collapse">

				<ul class="nav navbar-nav navbar-left">
					<!-- Moodle -->
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="https://moodle.wit.ie/course/view.php?id=192024" target="_blank"><img height="18pt" src="../../../style/misc/img/moodle_logo_on_blue.gif" /></a>
						</div>						
					</li>
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="https://moodle.wit.ie/course/view.php?id=192024" target="_blank"><img height="18pt" src="../../../style/misc/img/slack_logo.png" /></a>
						</div>						
					</li>
				</ul>

	      		<ul class="nav navbar-nav navbar-right">

					<!-- module home -->
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="../../../index.html"><span class="glyphicon glyphicon-home"></span></a>
						</div>						
					</li>
					
					<!-- topics -->
	        		<li>
						<div class="navbar-collapse collapse" id="b">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span class="glyphicon glyphicon-list-alt"></span>
									</a>
									<ul class="dropdown-menu" role="menu">
										<li class="dropdown-header">Topics</li>
										
										<li >
											<a href="../../../topics/01-Module_Introduction/index.html">Module Introduction</a>
										</li>
										
										<li >
											<a href="../../../topics/02-Feature_Engineering/index.html">Feature Engineering</a>
										</li>
										
										<li >
											<a href="../../../topics/03-Review_of_Model_Building/index.html">Review of Model Building</a>
										</li>
										
										<li >
											<a href="../../../topics/04-Hyperparameter_Tuning/index.html">Hyperparameter Tuning</a>
										</li>
										
										<li class="active">
											<a href="../../../topics/05-Ensemble_Learning/index.html">Ensemble Learning</a>
										</li>
										
										<li >
											<a href="../../../topics/06-Time_Series_Mining/index.html">Time Series Mining</a>
										</li>
										
										<li >
											<a href="../../../topics/21-Assignments/index.html">Assignments</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li>

					<!-- resources -->
	        		<li>
						<div class="navbar-collapse collapse" id="b">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span class="glyphicon glyphicon-th-list"></span>
									</a>
									<ul class="dropdown-menu" role="menu">
										<li class="dropdown-header">Resources</li>
										
										<li >
											<a href="../../../topics/05-Ensemble_Learning/index.html#01-Introduction_to_Ensemble_Learning">Introduction to Ensemble Learning</a>
										</li>
										
										<li class="active">
											<a href="../../../topics/05-Ensemble_Learning/index.html#21-Practical_05_-_Ensemble_Learners">Practical 05 - Ensemble Learners</a>
										</li>
										
										<li >
											<a href="../../../topics/05-Ensemble_Learning/index.html#22-Practical_06_-_Stacked_Models">Practical 06 - Stacked Models</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li>
								
					<!-- pages-->
	        		<li>
						<div class="navbar-collapse collapse" id="c">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span>XGBoost</span
									</a>
									<ul class="dropdown-menu" role="menu">
										
										<li >
											<a href="00-Outline.html">Outline</a>
										</li>
										
										<li >
											<a href="01-Datasets.html">Datasets</a>
										</li>
										
										<li >
											<a href="02-Preprocessing.html">Preprocessing</a>
										</li>
										
										<li >
											<a href="03-AdaBoost.html">AdaBoost</a>
										</li>
										
										<li >
											<a href="04-Gradient_Boosting.html">Gradient Boosting</a>
										</li>
										
										<li class="active">
											<a href="05-XGBoost.html">XGBoost</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li> 
					
	        	</ul>
			</div>
		</div>
	</div>

	<!-- contents -->
	<div class="container">
		
		<ul class="pager">
			
			<li class="previous"><a href="04-Gradient_Boosting.html">&larr; Previous (Gradient Boosting)</a></li>
			
			
			
			<li class="next disabled"><a>Next &rarr;</a></li>
			
		</ul>
		
		<h1>XGBoost</h1>
<p>XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. See <a href="https://xgboost.readthedocs.io/en/latest/">XGBoost documentation</a> here.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">xgboost</span> 
</code></pre></div>
</td></tr></table>
<p>Since XGBoost does not directly support multi-classification (you can implement your own customized objective class to achieve this), we use digit 1 and 2 to build a binary data set.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="c1"># filter the original data set</span>
<span class="n">criteria</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">criteria</span><span class="p">,</span> <span class="n">attribute_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">criteria</span><span class="p">,</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">X_train_val</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train_val</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train_val</span><span class="p">,</span> <span class="n">y_train_val</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_val</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
</td></tr></table>
<p>Now fit as usual</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">xgb</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span> <span class="n">booster</span><span class="o">=</span><span class="s1">&#39;gbtree&#39;</span><span class="p">)</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<p>Early stopping in XGBoost is much easier. There is a parameter called <code>early_stopping_rounds</code>. The model will train until the validation score stops improving. Validation error needs to decrease at least every <code>early_stopping_rounds</code> to continue training. </p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="n">xgb</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span> <span class="n">booster</span><span class="o">=</span><span class="s1">&#39;gbtree&#39;</span><span class="p">)</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)],</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
<span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation Accuracy:&quot;</span><span class="p">,</span> <span class="n">val_accuracy</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<h2>Additional Methods</h2>
<p>If you are interested in Boosting algorithm, you could read additional material:</p>
<ul>
<li><a href="https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf">LightGBM - Paper</a>, and <a href="https://lightgbm.readthedocs.io/en/latest/">LightGBM - Documentation</a>. </li>
<li><a href="https://arxiv.org/abs/1706.09516">CatBoost - Paper</a> and <a href="https://catboost.ai/docs/concepts/about.html">CatBoost - Documentation</a>.</li>
</ul>
		
		<ul class="pager">
			
			<li class="previous"><a href="04-Gradient_Boosting.html">&larr; Previous (Gradient Boosting)</a></li>
			
			
			
			<li class="next disabled"><a>Next &rarr;</a></li>
			
		</ul>

	</div>
	
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <script src="../../../style/bootstrap/js/bootstrap.min.js"></script>
	
  </body>
</html>